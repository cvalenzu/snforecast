{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow import constant_initializer\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import shutil\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _exponential_initializer(min, max, dtype=None):\n",
    "    def in_func(shape, dtype=dtype):\n",
    "        initializer = tf.random_uniform_initializer(\n",
    "                        tf.math.log(1.0),\n",
    "                        tf.math.log(100.0)\n",
    "                        )\n",
    "        return tf.math.exp(initializer(shape))\n",
    "    return in_func\n",
    "\n",
    "class PhasedLSTM(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 units,\n",
    "                 leak_rate=0.001,\n",
    "                 ratio_on=0.1,\n",
    "                 period_init_min=0.0,\n",
    "                 period_init_max=1000.0,\n",
    "                 rec_activation = tf.math.sigmoid,\n",
    "                 out_activation = tf.math.tanh,\n",
    "                 name='plstm',\n",
    "                 **kwargs):\n",
    "        super(PhasedLSTM, self).__init__(name=name)\n",
    "        \n",
    "        self.state_size = [units,units] #This change\n",
    "        self.output_size = units        #This change\n",
    "        \n",
    "        self.units = units\n",
    "        self._leak = leak_rate\n",
    "        self._ratio_on = ratio_on\n",
    "        self._rec_activation = rec_activation\n",
    "        self._out_activation = out_activation\n",
    "        self.period_init_min = period_init_min\n",
    "        self.period_init_max = period_init_max\n",
    "        \n",
    "        self.cell = tf.keras.layers.LSTMCell(units, **kwargs)\n",
    "\n",
    "    def _get_cycle_ratio(self, time, phase, period):\n",
    "        \"\"\"Compute the cycle ratio in the dtype of the time.\"\"\"\n",
    "        phase_casted = tf.cast(phase, dtype=time.dtype)\n",
    "        period_casted = tf.cast(period, dtype=time.dtype)\n",
    "        time = tf.reshape(time, [tf.shape(time)[0],1]) #This change\n",
    "        shifted_time = time - phase_casted\n",
    "        cycle_ratio = (shifted_time%period_casted) / period_casted\n",
    "        return tf.cast(cycle_ratio, dtype=tf.float32)        \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.period = self.add_weight(\n",
    "                        name=\"period\",\n",
    "                        shape=[self.units],\n",
    "                        initializer=_exponential_initializer(\n",
    "                                            self.period_init_min,\n",
    "                                            self.period_init_max),\n",
    "                        trainable=True)\n",
    "\n",
    "        self.phase = self.add_weight(name=\"phase\",\n",
    "                                     shape=[self.units],\n",
    "                                     initializer=tf.random_uniform_initializer(\n",
    "                                                         0.0,\n",
    "                                                         self.period),\n",
    "                                     trainable=True)\n",
    "        self.ratio_on = self.add_weight(name=\"ratio_on\",\n",
    "                                        shape=[self.units],\n",
    "                                        initializer=constant_initializer(self._ratio_on),\n",
    "                                        trainable=True)\n",
    "\n",
    "    def call(self, input, states):\n",
    "        inputs, times = input, input[:,0] #This change\n",
    "\n",
    "        # =================================\n",
    "        # CANDIDATE CELL AND HIDDEN STATE\n",
    "        # =================================\n",
    "        prev_hs, prev_cs = states\n",
    "        output, (hs, cs) = self.cell(inputs, states)\n",
    "\n",
    "        # =================================\n",
    "        # TIME GATE\n",
    "        # =================================\n",
    "        cycle_ratio = self._get_cycle_ratio(times, self.phase, self.period)\n",
    "\n",
    "        k_up = 2 * cycle_ratio / self.ratio_on\n",
    "        k_down = 2 - k_up\n",
    "        k_closed = self._leak * cycle_ratio\n",
    "\n",
    "        k = tf.where(cycle_ratio < self.ratio_on, k_down, k_closed)\n",
    "        k = tf.where(cycle_ratio < 0.5 * self.ratio_on, k_up, k)\n",
    "\n",
    "        # =================================\n",
    "        # UPDATE STATE USING TIME GATE VALUES\n",
    "        # =================================\n",
    "        new_h = k * hs + (1 - k) * prev_hs\n",
    "        new_c = k * cs + (1 - k) * prev_cs\n",
    "\n",
    "        return new_h, (new_h, new_c)\n",
    "\n",
    "    \n",
    "    \n",
    "class PhasedSNForecastModel(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps, features, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.features = features\n",
    "        self.dropout = dropout\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.mask = tf.keras.layers.Masking(mask_value=-1.0)    \n",
    "        self._init_dense()\n",
    "        self._init_recurrent()\n",
    "\n",
    "\n",
    "\n",
    "    def fowardpass(self, cells, states, denses, x, training=None):\n",
    "        for i,cell in enumerate(cells):\n",
    "            x, states[i] = cell(x, states=states[i],\n",
    "                      training=training)\n",
    "        for layer in denses:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x, states\n",
    "\n",
    "    def _warmup(self,rnn, denses, inputs):\n",
    "        x, *state = rnn(inputs)\n",
    "        for layer in denses:\n",
    "            x = layer(x)\n",
    "        return x, state\n",
    "\n",
    "    def warmups(self,inputs):\n",
    "#         prediction = self.rnn_batch_norm(inputs)\n",
    "        prediction,states = self._warmup(self.rnn,self.denses,inputs)\n",
    "        return prediction,states\n",
    "\n",
    "    def _init_recurrent(self):\n",
    "        cell1 = PhasedLSTM(self.units, dropout=self.dropout)\n",
    "        cell2 = tf.keras.layers.LSTMCell(self.units//2, dropout=self.dropout)\n",
    "        self.cells = [cell1]\n",
    "        self.rnn = tf.keras.layers.RNN(self.cells, return_state=True)\n",
    "\n",
    "    def _init_dense(self):\n",
    "        dense1 = tf.keras.layers.Dense(self.units//4, activation=\"tanh\")\n",
    "        dense2 = tf.keras.layers.Dense(self.units//8, activation=\"tanh\")\n",
    "        dense3 = tf.keras.layers.Dense(self.units//16, activation=\"tanh\")\n",
    "\n",
    "        out = tf.keras.layers.Dense(self.features, activation=\"linear\")\n",
    "        self.denses = [\n",
    "                dense1,\n",
    "                tf.keras.layers.Dropout(self.dropout),\n",
    "                dense2,\n",
    "                tf.keras.layers.Dropout(self.dropout),\n",
    "                dense3, \n",
    "                tf.keras.layers.Dropout(self.dropout), \n",
    "                out]\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        inputs = self.mask(inputs)\n",
    "        #Creating empty tensors for predictions\n",
    "        predictions = []\n",
    "        prediction, states = self.warmups(inputs)\n",
    "\n",
    "        #Saving first predictions\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        for n in range(1, self.out_steps):\n",
    "            prediction, states = self.fowardpass(self.cells, states, self.denses, prediction, training)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        #Stacking predictions\n",
    "        predictions = tf.stack(predictions)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PhasedSNForecastModel(units=150, out_steps=out_steps,features = 3)\n",
    "losses = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "model.compile(optimizer=\"rmsprop\", loss=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    masked_data = np.ma.masked_where(data < 0, data)\n",
    "    min_val = masked_data.min(axis=1)\n",
    "    max_val = masked_data.max(axis=1)\n",
    "    \n",
    "    for i in range(masked_data.shape[1]):\n",
    "        masked_data.data[:,i,:] = (masked_data.data[:,i,:] - min_val)/(max_val-min_val)\n",
    "    \n",
    "    return_data = masked_data.data\n",
    "    return_data[masked_data.mask] = -1\n",
    "    return return_data, min_val, max_val\n",
    "    \n",
    "def denormalize(data, min_val, max_val):\n",
    "    masked_data = np.ma.masked_where(data < 0, data)\n",
    "    \n",
    "    for i in range(masked_data.shape[1]):\n",
    "        masked_data.data[:,i,:] = (masked_data.data[:,i,:] * (max_val-min_val))  +  min_val\n",
    "    \n",
    "    return_data = masked_data.data\n",
    "    return_data[masked_data.mask] = -1\n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../data/padded_x_train.npy\")\n",
    "len_data = data.shape[1]\n",
    "data, data_min_val, data_max_val = normalize(data)\n",
    "X_train, y_train = data[:,:-out_steps,:],  data[:,-out_steps:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = np.load(\"../data/padded_x_val.npy\")\n",
    "len_data = data_val.shape[1]\n",
    "data_val, data_val_min_val, data_val_max_val = normalize(data_val)\n",
    "X_val, y_val = data_val[:,:-out_steps,:],  data_val[:,-out_steps:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = X_train\n",
    "outputs = y_train\n",
    "inputs_val = X_val\n",
    "outputs_val = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stops\n",
    "early_stop = tf.keras.callbacks.EarlyStopping( monitor='val_loss', min_delta=1e-10, patience=10)\n",
    "\n",
    "#Tensorboard\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\"../data/training/logs\")\n",
    "shutil.rmtree(\"../data/training/logs\",ignore_errors=True)\n",
    "#Checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"../data/training/model_checkpoints/checkpoint\", monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "callbacks = [tensorboard,checkpoint, early_stop] # mag_early_stop,fid_early_stop,dt_early_stop,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.5240WARNING:tensorflow:From /home/camilo/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "2/9 [=====>........................] - ETA: 2s - loss: 0.4928WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3011s vs `on_train_batch_end` time: 0.5174s). Check your callbacks.\n",
      "9/9 [==============================] - 4s 439ms/step - loss: 0.4198 - val_loss: 0.3190\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 0.3532 - val_loss: 0.2863\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 4s 428ms/step - loss: 0.3341 - val_loss: 0.2675\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 4s 419ms/step - loss: 0.3210 - val_loss: 0.2471\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 4s 410ms/step - loss: 0.3072 - val_loss: 0.2685\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 4s 409ms/step - loss: 0.2965 - val_loss: 0.2264\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 4s 411ms/step - loss: 0.2879 - val_loss: 0.2385\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 4s 438ms/step - loss: 0.2798 - val_loss: 0.2196\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 4s 426ms/step - loss: 0.2734 - val_loss: 0.2295\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 4s 413ms/step - loss: 0.2672 - val_loss: 0.2380\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 4s 422ms/step - loss: 0.2626 - val_loss: 0.2041\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 4s 418ms/step - loss: 0.2574 - val_loss: 0.2068\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 4s 415ms/step - loss: 0.2528 - val_loss: 0.2090\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 4s 414ms/step - loss: 0.2496 - val_loss: 0.2037\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 4s 425ms/step - loss: 0.2458 - val_loss: 0.2053\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 4s 443ms/step - loss: 0.2428 - val_loss: 0.2091\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 4s 420ms/step - loss: 0.2392 - val_loss: 0.1918\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 4s 411ms/step - loss: 0.2372 - val_loss: 0.2105\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 4s 424ms/step - loss: 0.2363 - val_loss: 0.1944\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 4s 498ms/step - loss: 0.2329 - val_loss: 0.1967\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 4s 443ms/step - loss: 0.2307 - val_loss: 0.2016\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 4s 421ms/step - loss: 0.2294 - val_loss: 0.1973\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 4s 404ms/step - loss: 0.2278 - val_loss: 0.1957\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 4s 404ms/step - loss: 0.2255 - val_loss: 0.1745\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 4s 404ms/step - loss: 0.2231 - val_loss: 0.1829\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 4s 404ms/step - loss: 0.2222 - val_loss: 0.1791\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 4s 408ms/step - loss: 0.2223 - val_loss: 0.1876\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 4s 397ms/step - loss: 0.2200 - val_loss: 0.1827\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 4s 403ms/step - loss: 0.2198 - val_loss: 0.1857\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 4s 408ms/step - loss: 0.2168 - val_loss: 0.1887\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 4s 403ms/step - loss: 0.2163 - val_loss: 0.1770\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 4s 397ms/step - loss: 0.2162 - val_loss: 0.1804\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 4s 404ms/step - loss: 0.2145 - val_loss: 0.1709\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 4s 405ms/step - loss: 0.2121 - val_loss: 0.1880\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 4s 409ms/step - loss: 0.2128 - val_loss: 0.1721\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 4s 397ms/step - loss: 0.2114 - val_loss: 0.1872\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 4s 403ms/step - loss: 0.2105 - val_loss: 0.1735\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 4s 414ms/step - loss: 0.2076 - val_loss: 0.1830\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 4s 400ms/step - loss: 0.2085 - val_loss: 0.1781\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 4s 401ms/step - loss: 0.2073 - val_loss: 0.1759\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 4s 402ms/step - loss: 0.2067 - val_loss: 0.1743\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 4s 402ms/step - loss: 0.2049 - val_loss: 0.1722\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 4s 401ms/step - loss: 0.2051 - val_loss: 0.1791\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS=1000\n",
    "history = model.fit(inputs,outputs,\n",
    "                    batch_size=300, \n",
    "                    epochs=MAX_EPOCHS, \n",
    "                    validation_data=(inputs_val,outputs_val), \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4db884b873a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/training/history_model.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "json.dump(history_dict, open(\"../data/training/history_model.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-11b2ca6e19b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/sn_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"../data/sn_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
